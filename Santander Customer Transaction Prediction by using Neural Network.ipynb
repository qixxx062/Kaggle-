{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transaction Prediction\n",
    "\n",
    "At Santander our mission is to help people and businesses prosper. We are always looking for ways to help our customers understand their financial health and identify which products and services might help them achieve their monetary goals.\n",
    "\n",
    "Our data science team is continually challenging our machine learning algorithms, working with the global data science community to make sure we can more accurately identify new ways to solve our most common challenge, binary classification problems such as: is a customer satisfied? Will a customer buy this product? Can a customer pay this loan?\n",
    "\n",
    "In this challenge, we invite Kagglers to help us identify which customers will make a specific transaction in the future, irrespective of the amount of money transacted. The data provided for this competition has the same structure as the real data we have available to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Content\n",
    "\n",
    "* Load packages\n",
    "* EDA\n",
    "* Model\n",
    "* Evaluation\n",
    "* Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, KFold,train_test_split,GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"C://Users//nqi200//Desktop/DSA/\"\n",
    "data_dir = main_dir + \"/data\"\n",
    "\n",
    "os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train data...\n",
      "It takes 7.01 seconds to read 'train.csv'.\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading train data...\")\n",
    "start = time.time()\n",
    "train = pd.read_csv('train.csv')\n",
    "end = time.time()\n",
    "\n",
    "print(\"It takes {0:.2f} seconds to read 'train.csv'.\".format(end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading test data...\n",
      "It takes 6.74 seconds to read 'test.csv'.\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading test data...\")\n",
    "start = time.time()\n",
    "test_eva = pd.read_csv('test.csv')\n",
    "end = time.time()\n",
    "\n",
    "print(\"It takes {0:.2f} seconds to read 'test.csv'.\".format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 200000 entries, 0 to 199999\n",
      "Columns: 202 entries, ID_code to var_199\n",
      "dtypes: float64(200), int64(1), object(1)\n",
      "memory usage: 308.2+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>144481</th>\n",
       "      <td>train_144481</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0624</td>\n",
       "      <td>-7.2332</td>\n",
       "      <td>12.3246</td>\n",
       "      <td>7.7310</td>\n",
       "      <td>10.1362</td>\n",
       "      <td>-1.6005</td>\n",
       "      <td>3.3656</td>\n",
       "      <td>20.3071</td>\n",
       "      <td>...</td>\n",
       "      <td>4.5242</td>\n",
       "      <td>7.0857</td>\n",
       "      <td>-0.4390</td>\n",
       "      <td>5.6460</td>\n",
       "      <td>17.1652</td>\n",
       "      <td>-0.5625</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>10.1711</td>\n",
       "      <td>14.9745</td>\n",
       "      <td>-11.8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63830</th>\n",
       "      <td>train_63830</td>\n",
       "      <td>0</td>\n",
       "      <td>8.8304</td>\n",
       "      <td>-2.1175</td>\n",
       "      <td>17.1229</td>\n",
       "      <td>3.4076</td>\n",
       "      <td>9.7753</td>\n",
       "      <td>0.1624</td>\n",
       "      <td>4.3116</td>\n",
       "      <td>15.1633</td>\n",
       "      <td>...</td>\n",
       "      <td>1.1702</td>\n",
       "      <td>3.3899</td>\n",
       "      <td>0.4775</td>\n",
       "      <td>5.5927</td>\n",
       "      <td>18.8016</td>\n",
       "      <td>-1.4285</td>\n",
       "      <td>-3.1060</td>\n",
       "      <td>9.5910</td>\n",
       "      <td>14.6214</td>\n",
       "      <td>-14.3529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>train_3848</td>\n",
       "      <td>0</td>\n",
       "      <td>11.8585</td>\n",
       "      <td>-6.4825</td>\n",
       "      <td>8.5970</td>\n",
       "      <td>7.0946</td>\n",
       "      <td>11.3251</td>\n",
       "      <td>-10.8982</td>\n",
       "      <td>6.8775</td>\n",
       "      <td>18.2627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8799</td>\n",
       "      <td>6.0928</td>\n",
       "      <td>3.9597</td>\n",
       "      <td>-5.1066</td>\n",
       "      <td>23.4852</td>\n",
       "      <td>-3.0663</td>\n",
       "      <td>1.2430</td>\n",
       "      <td>10.2610</td>\n",
       "      <td>20.7790</td>\n",
       "      <td>11.8686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147779</th>\n",
       "      <td>train_147779</td>\n",
       "      <td>0</td>\n",
       "      <td>9.3866</td>\n",
       "      <td>-6.3628</td>\n",
       "      <td>8.7763</td>\n",
       "      <td>8.1103</td>\n",
       "      <td>10.6564</td>\n",
       "      <td>-16.0272</td>\n",
       "      <td>6.3845</td>\n",
       "      <td>15.4696</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0928</td>\n",
       "      <td>4.0358</td>\n",
       "      <td>2.4124</td>\n",
       "      <td>8.9069</td>\n",
       "      <td>14.2732</td>\n",
       "      <td>1.3097</td>\n",
       "      <td>0.2994</td>\n",
       "      <td>8.6374</td>\n",
       "      <td>23.3513</td>\n",
       "      <td>5.1667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157903</th>\n",
       "      <td>train_157903</td>\n",
       "      <td>1</td>\n",
       "      <td>9.0975</td>\n",
       "      <td>-10.6693</td>\n",
       "      <td>11.2019</td>\n",
       "      <td>3.0495</td>\n",
       "      <td>9.1570</td>\n",
       "      <td>4.4450</td>\n",
       "      <td>7.5625</td>\n",
       "      <td>14.7152</td>\n",
       "      <td>...</td>\n",
       "      <td>9.8399</td>\n",
       "      <td>4.7888</td>\n",
       "      <td>2.5088</td>\n",
       "      <td>5.3962</td>\n",
       "      <td>20.7798</td>\n",
       "      <td>-1.9140</td>\n",
       "      <td>10.6896</td>\n",
       "      <td>8.9180</td>\n",
       "      <td>8.6999</td>\n",
       "      <td>-12.2614</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             ID_code  target    var_0    var_1    var_2   var_3    var_4  \\\n",
       "144481  train_144481       1   7.0624  -7.2332  12.3246  7.7310  10.1362   \n",
       "63830    train_63830       0   8.8304  -2.1175  17.1229  3.4076   9.7753   \n",
       "3848      train_3848       0  11.8585  -6.4825   8.5970  7.0946  11.3251   \n",
       "147779  train_147779       0   9.3866  -6.3628   8.7763  8.1103  10.6564   \n",
       "157903  train_157903       1   9.0975 -10.6693  11.2019  3.0495   9.1570   \n",
       "\n",
       "          var_5   var_6    var_7  ...  var_190  var_191  var_192  var_193  \\\n",
       "144481  -1.6005  3.3656  20.3071  ...   4.5242   7.0857  -0.4390   5.6460   \n",
       "63830    0.1624  4.3116  15.1633  ...   1.1702   3.3899   0.4775   5.5927   \n",
       "3848   -10.8982  6.8775  18.2627  ...   0.8799   6.0928   3.9597  -5.1066   \n",
       "147779 -16.0272  6.3845  15.4696  ...   4.0928   4.0358   2.4124   8.9069   \n",
       "157903   4.4450  7.5625  14.7152  ...   9.8399   4.7888   2.5088   5.3962   \n",
       "\n",
       "        var_194  var_195  var_196  var_197  var_198  var_199  \n",
       "144481  17.1652  -0.5625   0.7888  10.1711  14.9745 -11.8760  \n",
       "63830   18.8016  -1.4285  -3.1060   9.5910  14.6214 -14.3529  \n",
       "3848    23.4852  -3.0663   1.2430  10.2610  20.7790  11.8686  \n",
       "147779  14.2732   1.3097   0.2994   8.6374  23.3513   5.1667  \n",
       "157903  20.7798  -1.9140  10.6896   8.9180   8.6999 -12.2614  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample(n =5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_0</td>\n",
       "      <td>11.0656</td>\n",
       "      <td>7.7798</td>\n",
       "      <td>12.9536</td>\n",
       "      <td>9.4292</td>\n",
       "      <td>11.4327</td>\n",
       "      <td>-2.3805</td>\n",
       "      <td>5.8493</td>\n",
       "      <td>18.2675</td>\n",
       "      <td>2.1337</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.1556</td>\n",
       "      <td>11.8495</td>\n",
       "      <td>-1.4300</td>\n",
       "      <td>2.4508</td>\n",
       "      <td>13.7112</td>\n",
       "      <td>2.4669</td>\n",
       "      <td>4.3654</td>\n",
       "      <td>10.7200</td>\n",
       "      <td>15.4722</td>\n",
       "      <td>-8.7197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_1</td>\n",
       "      <td>8.5304</td>\n",
       "      <td>1.2543</td>\n",
       "      <td>11.3047</td>\n",
       "      <td>5.1858</td>\n",
       "      <td>9.1974</td>\n",
       "      <td>-4.0117</td>\n",
       "      <td>6.0196</td>\n",
       "      <td>18.6316</td>\n",
       "      <td>-4.4131</td>\n",
       "      <td>...</td>\n",
       "      <td>10.6165</td>\n",
       "      <td>8.8349</td>\n",
       "      <td>0.9403</td>\n",
       "      <td>10.1282</td>\n",
       "      <td>15.5765</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>-1.4852</td>\n",
       "      <td>9.8714</td>\n",
       "      <td>19.1293</td>\n",
       "      <td>-20.9760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_2</td>\n",
       "      <td>5.4827</td>\n",
       "      <td>-10.3581</td>\n",
       "      <td>10.1407</td>\n",
       "      <td>7.0479</td>\n",
       "      <td>10.2628</td>\n",
       "      <td>9.8052</td>\n",
       "      <td>4.8950</td>\n",
       "      <td>20.2537</td>\n",
       "      <td>1.5233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.7484</td>\n",
       "      <td>10.9935</td>\n",
       "      <td>1.9803</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>12.9813</td>\n",
       "      <td>2.1281</td>\n",
       "      <td>-7.1086</td>\n",
       "      <td>7.0618</td>\n",
       "      <td>19.8956</td>\n",
       "      <td>-23.1794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_3</td>\n",
       "      <td>8.5374</td>\n",
       "      <td>-1.3222</td>\n",
       "      <td>12.0220</td>\n",
       "      <td>6.5749</td>\n",
       "      <td>8.8458</td>\n",
       "      <td>3.1744</td>\n",
       "      <td>4.9397</td>\n",
       "      <td>20.5660</td>\n",
       "      <td>3.3755</td>\n",
       "      <td>...</td>\n",
       "      <td>9.5702</td>\n",
       "      <td>9.0766</td>\n",
       "      <td>1.6580</td>\n",
       "      <td>3.5813</td>\n",
       "      <td>15.1874</td>\n",
       "      <td>3.1656</td>\n",
       "      <td>3.9567</td>\n",
       "      <td>9.2295</td>\n",
       "      <td>13.0168</td>\n",
       "      <td>-4.2108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_4</td>\n",
       "      <td>11.7058</td>\n",
       "      <td>-0.1327</td>\n",
       "      <td>14.1295</td>\n",
       "      <td>7.7506</td>\n",
       "      <td>9.1035</td>\n",
       "      <td>-8.5848</td>\n",
       "      <td>6.8595</td>\n",
       "      <td>10.6048</td>\n",
       "      <td>2.9890</td>\n",
       "      <td>...</td>\n",
       "      <td>4.2259</td>\n",
       "      <td>9.1723</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>3.3778</td>\n",
       "      <td>19.5542</td>\n",
       "      <td>-0.2860</td>\n",
       "      <td>-5.1612</td>\n",
       "      <td>7.2882</td>\n",
       "      <td>13.9260</td>\n",
       "      <td>-9.1846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID_code    var_0    var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  test_0  11.0656   7.7798  12.9536  9.4292  11.4327 -2.3805  5.8493   \n",
       "1  test_1   8.5304   1.2543  11.3047  5.1858   9.1974 -4.0117  6.0196   \n",
       "2  test_2   5.4827 -10.3581  10.1407  7.0479  10.2628  9.8052  4.8950   \n",
       "3  test_3   8.5374  -1.3222  12.0220  6.5749   8.8458  3.1744  4.9397   \n",
       "4  test_4  11.7058  -0.1327  14.1295  7.7506   9.1035 -8.5848  6.8595   \n",
       "\n",
       "     var_7   var_8  ...  var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.2675  2.1337  ...  -2.1556  11.8495  -1.4300   2.4508  13.7112   2.4669   \n",
       "1  18.6316 -4.4131  ...  10.6165   8.8349   0.9403  10.1282  15.5765   0.4773   \n",
       "2  20.2537  1.5233  ...  -0.7484  10.9935   1.9803   2.1800  12.9813   2.1281   \n",
       "3  20.5660  3.3755  ...   9.5702   9.0766   1.6580   3.5813  15.1874   3.1656   \n",
       "4  10.6048  2.9890  ...   4.2259   9.1723   1.2835   3.3778  19.5542  -0.2860   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   4.3654  10.7200  15.4722  -8.7197  \n",
       "1  -1.4852   9.8714  19.1293 -20.9760  \n",
       "2  -7.1086   7.0618  19.8956 -23.1794  \n",
       "3   3.9567   9.2295  13.0168  -4.2108  \n",
       "4  -5.1612   7.2882  13.9260  -9.1846  \n",
       "\n",
       "[5 rows x 201 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eva.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 202), (200000, 201))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test_eva.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.100490</td>\n",
       "      <td>10.679914</td>\n",
       "      <td>-1.627622</td>\n",
       "      <td>10.715192</td>\n",
       "      <td>6.796529</td>\n",
       "      <td>11.078333</td>\n",
       "      <td>-5.065317</td>\n",
       "      <td>5.408949</td>\n",
       "      <td>16.545850</td>\n",
       "      <td>0.284162</td>\n",
       "      <td>...</td>\n",
       "      <td>3.234440</td>\n",
       "      <td>7.438408</td>\n",
       "      <td>1.927839</td>\n",
       "      <td>3.331774</td>\n",
       "      <td>17.993784</td>\n",
       "      <td>-0.142088</td>\n",
       "      <td>2.303335</td>\n",
       "      <td>8.908158</td>\n",
       "      <td>15.870720</td>\n",
       "      <td>-3.326537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.300653</td>\n",
       "      <td>3.040051</td>\n",
       "      <td>4.050044</td>\n",
       "      <td>2.640894</td>\n",
       "      <td>2.043319</td>\n",
       "      <td>1.623150</td>\n",
       "      <td>7.863267</td>\n",
       "      <td>0.866607</td>\n",
       "      <td>3.418076</td>\n",
       "      <td>3.332634</td>\n",
       "      <td>...</td>\n",
       "      <td>4.559922</td>\n",
       "      <td>3.023272</td>\n",
       "      <td>1.478423</td>\n",
       "      <td>3.992030</td>\n",
       "      <td>3.135162</td>\n",
       "      <td>1.429372</td>\n",
       "      <td>5.454369</td>\n",
       "      <td>0.921625</td>\n",
       "      <td>3.010945</td>\n",
       "      <td>10.438015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408400</td>\n",
       "      <td>-15.043400</td>\n",
       "      <td>2.117100</td>\n",
       "      <td>-0.040200</td>\n",
       "      <td>5.074800</td>\n",
       "      <td>-32.562600</td>\n",
       "      <td>2.347300</td>\n",
       "      <td>5.349700</td>\n",
       "      <td>-10.505500</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.093300</td>\n",
       "      <td>-2.691700</td>\n",
       "      <td>-3.814500</td>\n",
       "      <td>-11.783400</td>\n",
       "      <td>8.694400</td>\n",
       "      <td>-5.261000</td>\n",
       "      <td>-14.209600</td>\n",
       "      <td>5.960600</td>\n",
       "      <td>6.299300</td>\n",
       "      <td>-38.852800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.453850</td>\n",
       "      <td>-4.740025</td>\n",
       "      <td>8.722475</td>\n",
       "      <td>5.254075</td>\n",
       "      <td>9.883175</td>\n",
       "      <td>-11.200350</td>\n",
       "      <td>4.767700</td>\n",
       "      <td>13.943800</td>\n",
       "      <td>-2.317800</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058825</td>\n",
       "      <td>5.157400</td>\n",
       "      <td>0.889775</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>15.629800</td>\n",
       "      <td>-1.170700</td>\n",
       "      <td>-1.946925</td>\n",
       "      <td>8.252800</td>\n",
       "      <td>13.829700</td>\n",
       "      <td>-11.208475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.524750</td>\n",
       "      <td>-1.608050</td>\n",
       "      <td>10.580000</td>\n",
       "      <td>6.825000</td>\n",
       "      <td>11.108250</td>\n",
       "      <td>-4.833150</td>\n",
       "      <td>5.385100</td>\n",
       "      <td>16.456800</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>...</td>\n",
       "      <td>3.203600</td>\n",
       "      <td>7.347750</td>\n",
       "      <td>1.901300</td>\n",
       "      <td>3.396350</td>\n",
       "      <td>17.957950</td>\n",
       "      <td>-0.172700</td>\n",
       "      <td>2.408900</td>\n",
       "      <td>8.888200</td>\n",
       "      <td>15.934050</td>\n",
       "      <td>-2.819550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.758200</td>\n",
       "      <td>1.358625</td>\n",
       "      <td>12.516700</td>\n",
       "      <td>8.324100</td>\n",
       "      <td>12.261125</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>6.003000</td>\n",
       "      <td>19.102900</td>\n",
       "      <td>2.937900</td>\n",
       "      <td>...</td>\n",
       "      <td>6.406200</td>\n",
       "      <td>9.512525</td>\n",
       "      <td>2.949500</td>\n",
       "      <td>6.205800</td>\n",
       "      <td>20.396525</td>\n",
       "      <td>0.829600</td>\n",
       "      <td>6.556725</td>\n",
       "      <td>9.593300</td>\n",
       "      <td>18.064725</td>\n",
       "      <td>4.836800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.315000</td>\n",
       "      <td>10.376800</td>\n",
       "      <td>19.353000</td>\n",
       "      <td>13.188300</td>\n",
       "      <td>16.671400</td>\n",
       "      <td>17.251600</td>\n",
       "      <td>8.447700</td>\n",
       "      <td>27.691800</td>\n",
       "      <td>10.151300</td>\n",
       "      <td>...</td>\n",
       "      <td>18.440900</td>\n",
       "      <td>16.716500</td>\n",
       "      <td>8.402400</td>\n",
       "      <td>18.281800</td>\n",
       "      <td>27.928800</td>\n",
       "      <td>4.272900</td>\n",
       "      <td>18.321500</td>\n",
       "      <td>12.000400</td>\n",
       "      <td>26.079100</td>\n",
       "      <td>28.500700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              target          var_0          var_1          var_2  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        0.100490      10.679914      -1.627622      10.715192   \n",
       "std         0.300653       3.040051       4.050044       2.640894   \n",
       "min         0.000000       0.408400     -15.043400       2.117100   \n",
       "25%         0.000000       8.453850      -4.740025       8.722475   \n",
       "50%         0.000000      10.524750      -1.608050      10.580000   \n",
       "75%         0.000000      12.758200       1.358625      12.516700   \n",
       "max         1.000000      20.315000      10.376800      19.353000   \n",
       "\n",
       "               var_3          var_4          var_5          var_6  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        6.796529      11.078333      -5.065317       5.408949   \n",
       "std         2.043319       1.623150       7.863267       0.866607   \n",
       "min        -0.040200       5.074800     -32.562600       2.347300   \n",
       "25%         5.254075       9.883175     -11.200350       4.767700   \n",
       "50%         6.825000      11.108250      -4.833150       5.385100   \n",
       "75%         8.324100      12.261125       0.924800       6.003000   \n",
       "max        13.188300      16.671400      17.251600       8.447700   \n",
       "\n",
       "               var_7          var_8  ...        var_190        var_191  \\\n",
       "count  200000.000000  200000.000000  ...  200000.000000  200000.000000   \n",
       "mean       16.545850       0.284162  ...       3.234440       7.438408   \n",
       "std         3.418076       3.332634  ...       4.559922       3.023272   \n",
       "min         5.349700     -10.505500  ...     -14.093300      -2.691700   \n",
       "25%        13.943800      -2.317800  ...      -0.058825       5.157400   \n",
       "50%        16.456800       0.393700  ...       3.203600       7.347750   \n",
       "75%        19.102900       2.937900  ...       6.406200       9.512525   \n",
       "max        27.691800      10.151300  ...      18.440900      16.716500   \n",
       "\n",
       "             var_192        var_193        var_194        var_195  \\\n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000   \n",
       "mean        1.927839       3.331774      17.993784      -0.142088   \n",
       "std         1.478423       3.992030       3.135162       1.429372   \n",
       "min        -3.814500     -11.783400       8.694400      -5.261000   \n",
       "25%         0.889775       0.584600      15.629800      -1.170700   \n",
       "50%         1.901300       3.396350      17.957950      -0.172700   \n",
       "75%         2.949500       6.205800      20.396525       0.829600   \n",
       "max         8.402400      18.281800      27.928800       4.272900   \n",
       "\n",
       "             var_196        var_197        var_198        var_199  \n",
       "count  200000.000000  200000.000000  200000.000000  200000.000000  \n",
       "mean        2.303335       8.908158      15.870720      -3.326537  \n",
       "std         5.454369       0.921625       3.010945      10.438015  \n",
       "min       -14.209600       5.960600       6.299300     -38.852800  \n",
       "25%        -1.946925       8.252800      13.829700     -11.208475  \n",
       "50%         2.408900       8.888200      15.934050      -2.819550  \n",
       "75%         6.556725       9.593300      18.064725       4.836800  \n",
       "max        18.321500      12.000400      26.079100      28.500700  \n",
       "\n",
       "[8 rows x 201 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train contains:\n",
    "\n",
    "* ID_code (string);\n",
    "* target;\n",
    "* 200 numerical variables, named from var_0 to var_199;\n",
    "\n",
    "\n",
    "Test contains:\n",
    "\n",
    "* ID_code (string);\n",
    "* 200 numerical variables, named from var_0 to var_199;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    179902\n",
       "1     20098\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(train['target']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['target', 'ID_code'], axis=1)\n",
    "y = train.loc[:,'target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>var_8</th>\n",
       "      <th>var_9</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>-4.9200</td>\n",
       "      <td>5.7470</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>3.1468</td>\n",
       "      <td>8.0851</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>-4.9193</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>-5.8609</td>\n",
       "      <td>8.2450</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>6.2654</td>\n",
       "      <td>7.6784</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     var_0   var_1    var_2   var_3    var_4   var_5   var_6    var_7   var_8  \\\n",
       "0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187  18.6266 -4.9200   \n",
       "1  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208  16.5338  3.1468   \n",
       "2   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427  14.6155 -4.9193   \n",
       "3  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428  14.9250 -5.8609   \n",
       "4   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405  19.2514  6.2654   \n",
       "\n",
       "    var_9  ...  var_190  var_191  var_192  var_193  var_194  var_195  var_196  \\\n",
       "0  5.7470  ...   4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   7.8784   \n",
       "1  8.0851  ...   7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   8.1267   \n",
       "2  5.9525  ...   2.9057   9.7905   1.6704   1.6858  21.6042   3.1417  -6.5213   \n",
       "3  8.2450  ...   4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706  -2.9275   \n",
       "4  7.6784  ...  -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   3.9267   \n",
       "\n",
       "   var_197  var_198  var_199  \n",
       "0   8.5635  12.7803  -1.0914  \n",
       "1   8.7889  18.3560   1.9518  \n",
       "2   8.2675  14.7222   0.3965  \n",
       "3  10.2922  17.9697  -8.9996  \n",
       "4   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scaling \n",
    "scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, \n",
    "                                                    y, \n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Neural Network \n",
    "\n",
    "* Using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textwrap import wrap\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Simple NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_simple = MLPClassifier(alpha=1e-5, \n",
    "                        hidden_layer_sizes=(200), \n",
    "                        solver='lbfgs',\n",
    "                        random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_nn_simple = nn_simple.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9146\n"
     ]
    }
   ],
   "source": [
    "acc_train_nn_simple = fit_nn_simple.score(X_train, y_train)\n",
    "\n",
    "print (\"Train Accuracy:\", acc_train_nn_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_simple = fit_nn_simple.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6278337142841308"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_simple)\n",
    "\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Use RandomizedSearchCV to optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the best partameters by using RandomizedSearchCV\n",
    "parameters_nn = {'solver': ['lbfgs'], \n",
    "              'max_iter': [100,200], \n",
    "              'alpha': 10.0 ** -np.arange(1, 7), \n",
    "            'hidden_layer_sizes':np.arange(5, 21)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_random = RandomizedSearchCV(MLPClassifier(), \n",
    "                       parameters_nn, \n",
    "                       n_jobs=-1,\n",
    "                       random_state =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nqi200\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "          estimator=MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=10, n_jobs=-1,\n",
       "          param_distributions={'solver': ['lbfgs'], 'max_iter': [100, 200], 'alpha': array([1.e-01, 1.e-02, 1.e-03, 1.e-04, 1.e-05, 1.e-06]), 'hidden_layer_sizes': array([ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20])},\n",
       "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'solver': 'lbfgs', 'max_iter': 200, 'hidden_layer_sizes': 5, 'alpha': 1e-06}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best parameters\n",
    "nn_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_best = MLPClassifier(alpha=1e-6, \n",
    "                        hidden_layer_sizes=(5), \n",
    "                        max_iter=200,\n",
    "                        solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_nn_best = nn_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_best = fit_nn_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9146\n"
     ]
    }
   ],
   "source": [
    "acc_train_nn_best = fit_nn_best.score(X_train, y_train)\n",
    "\n",
    "print (\"Train Accuracy:\", acc_train_nn_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6285848585896441"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#AUC\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_best)\n",
    "\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the model\n",
    "keras_nn= Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add first input layer with 1 hidden layer\n",
    "keras_nn.add(Dense(2000, #neurons for hiddenlayers\n",
    "               input_dim = X_train.shape[1], # number of variables\n",
    "               activation ='relu'\n",
    "              ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine the number of layers in the model\n",
    "keras_nn.add(Dense(1600,activation ='relu'))\n",
    "keras_nn.add(Dense(400, activation='relu'))\n",
    "\n",
    "\n",
    "keras_nn.add(Dense(1, activation ='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile model\n",
    "keras_nn.compile(loss ='binary_crossentropy', \n",
    "                 optimizer='adam',\n",
    "                metrics =['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 2000)              402000    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1600)              3201600   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 400)               640400    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 4,244,401\n",
      "Trainable params: 4,244,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 40s - loss: 0.3005 - acc: 0.8956\n",
      "Epoch 2/100\n",
      " - 39s - loss: 0.2447 - acc: 0.9102\n",
      "Epoch 3/100\n",
      " - 40s - loss: 0.2378 - acc: 0.9122\n",
      "Epoch 4/100\n",
      " - 39s - loss: 0.2400 - acc: 0.9116\n",
      "Epoch 5/100\n",
      " - 41s - loss: 0.2364 - acc: 0.9126\n",
      "Epoch 6/100\n",
      " - 39s - loss: 0.2362 - acc: 0.9128\n",
      "Epoch 7/100\n",
      " - 40s - loss: 0.2351 - acc: 0.9131\n",
      "Epoch 8/100\n",
      " - 39s - loss: 0.2368 - acc: 0.9127\n",
      "Epoch 9/100\n",
      " - 39s - loss: 0.2360 - acc: 0.9125\n",
      "Epoch 10/100\n",
      " - 40s - loss: 0.2357 - acc: 0.9128\n",
      "Epoch 11/100\n",
      " - 39s - loss: 0.2351 - acc: 0.9127\n",
      "Epoch 12/100\n",
      " - 39s - loss: 0.2407 - acc: 0.9113\n",
      "Epoch 13/100\n",
      " - 40s - loss: 0.2350 - acc: 0.9137\n",
      "Epoch 14/100\n",
      " - 39s - loss: 0.2337 - acc: 0.9139\n",
      "Epoch 15/100\n",
      " - 40s - loss: 0.2350 - acc: 0.9132\n",
      "Epoch 16/100\n",
      " - 40s - loss: 0.2358 - acc: 0.9133\n",
      "Epoch 17/100\n",
      " - 41s - loss: 0.2355 - acc: 0.9128\n",
      "Epoch 18/100\n",
      " - 42s - loss: 0.2355 - acc: 0.9129\n",
      "Epoch 19/100\n",
      " - 39s - loss: 0.2347 - acc: 0.9134\n",
      "Epoch 20/100\n",
      " - 40s - loss: 0.2341 - acc: 0.9136\n",
      "Epoch 21/100\n",
      " - 40s - loss: 0.2324 - acc: 0.9139\n",
      "Epoch 22/100\n",
      " - 40s - loss: 0.2348 - acc: 0.9137\n",
      "Epoch 23/100\n",
      " - 41s - loss: 0.2326 - acc: 0.9140\n",
      "Epoch 24/100\n",
      " - 42s - loss: 0.2322 - acc: 0.9140\n",
      "Epoch 25/100\n",
      " - 44s - loss: 0.2350 - acc: 0.9134\n",
      "Epoch 26/100\n",
      " - 45s - loss: 0.2328 - acc: 0.9140\n",
      "Epoch 27/100\n",
      " - 45s - loss: 0.2341 - acc: 0.9134\n",
      "Epoch 28/100\n",
      " - 46s - loss: 0.2327 - acc: 0.9142\n",
      "Epoch 29/100\n",
      " - 43s - loss: 0.2336 - acc: 0.9136\n",
      "Epoch 30/100\n",
      " - 40s - loss: 0.2323 - acc: 0.9143\n",
      "Epoch 31/100\n",
      " - 40s - loss: 0.2317 - acc: 0.9137\n",
      "Epoch 32/100\n",
      " - 40s - loss: 0.2316 - acc: 0.9139\n",
      "Epoch 33/100\n",
      " - 38s - loss: 0.2350 - acc: 0.9128\n",
      "Epoch 34/100\n",
      " - 39s - loss: 0.2312 - acc: 0.9143\n",
      "Epoch 35/100\n",
      " - 40s - loss: 0.2335 - acc: 0.9137\n",
      "Epoch 36/100\n",
      " - 39s - loss: 0.2310 - acc: 0.9145\n",
      "Epoch 37/100\n",
      " - 40s - loss: 0.2321 - acc: 0.9142\n",
      "Epoch 38/100\n",
      " - 41s - loss: 0.2319 - acc: 0.9138\n",
      "Epoch 39/100\n",
      " - 38s - loss: 0.2317 - acc: 0.9142\n",
      "Epoch 40/100\n",
      " - 38s - loss: 0.2310 - acc: 0.9142\n",
      "Epoch 41/100\n",
      " - 39s - loss: 0.2299 - acc: 0.9146\n",
      "Epoch 42/100\n",
      " - 38s - loss: 0.2315 - acc: 0.9141\n",
      "Epoch 43/100\n",
      " - 38s - loss: 0.2300 - acc: 0.9146\n",
      "Epoch 44/100\n",
      " - 39s - loss: 0.2303 - acc: 0.9146\n",
      "Epoch 45/100\n",
      " - 38s - loss: 0.2300 - acc: 0.9145\n",
      "Epoch 46/100\n",
      " - 39s - loss: 0.2298 - acc: 0.9149\n",
      "Epoch 47/100\n",
      " - 39s - loss: 0.2295 - acc: 0.9151\n",
      "Epoch 48/100\n",
      " - 39s - loss: 0.2307 - acc: 0.9143\n",
      "Epoch 49/100\n",
      " - 43s - loss: 0.2290 - acc: 0.9147\n",
      "Epoch 50/100\n",
      " - 41s - loss: 0.2285 - acc: 0.9148\n",
      "Epoch 51/100\n",
      " - 39s - loss: 0.2267 - acc: 0.9156\n",
      "Epoch 52/100\n",
      " - 39s - loss: 0.2272 - acc: 0.9152\n",
      "Epoch 53/100\n",
      " - 40s - loss: 0.2299 - acc: 0.9138\n",
      "Epoch 54/100\n",
      " - 39s - loss: 0.2270 - acc: 0.9156\n",
      "Epoch 55/100\n",
      " - 41s - loss: 0.2262 - acc: 0.9157\n",
      "Epoch 56/100\n",
      " - 42s - loss: 0.2266 - acc: 0.9156\n",
      "Epoch 57/100\n",
      " - 41s - loss: 0.2265 - acc: 0.9152\n",
      "Epoch 58/100\n",
      " - 42s - loss: 0.2277 - acc: 0.9151\n",
      "Epoch 59/100\n",
      " - 42s - loss: 0.2257 - acc: 0.9157\n",
      "Epoch 60/100\n",
      " - 41s - loss: 0.2250 - acc: 0.9160\n",
      "Epoch 61/100\n",
      " - 40s - loss: 0.2272 - acc: 0.9154\n",
      "Epoch 62/100\n",
      " - 41s - loss: 0.2240 - acc: 0.9162\n",
      "Epoch 63/100\n",
      " - 41s - loss: 0.2251 - acc: 0.9160\n",
      "Epoch 64/100\n",
      " - 40s - loss: 0.2282 - acc: 0.9146\n",
      "Epoch 65/100\n",
      " - 41s - loss: 0.2251 - acc: 0.9156\n",
      "Epoch 66/100\n",
      " - 40s - loss: 0.2250 - acc: 0.9155\n",
      "Epoch 67/100\n",
      " - 42s - loss: 0.2237 - acc: 0.9164\n",
      "Epoch 68/100\n",
      " - 41s - loss: 0.2240 - acc: 0.9159\n",
      "Epoch 69/100\n",
      " - 41s - loss: 0.2230 - acc: 0.9164\n",
      "Epoch 70/100\n",
      " - 42s - loss: 0.2231 - acc: 0.9161\n",
      "Epoch 71/100\n",
      " - 41s - loss: 0.2234 - acc: 0.9160\n",
      "Epoch 72/100\n",
      " - 41s - loss: 0.2217 - acc: 0.9164\n",
      "Epoch 73/100\n",
      " - 39s - loss: 0.2232 - acc: 0.9164\n",
      "Epoch 74/100\n",
      " - 41s - loss: 0.2224 - acc: 0.9166\n",
      "Epoch 75/100\n",
      " - 41s - loss: 0.2219 - acc: 0.9166\n",
      "Epoch 76/100\n",
      " - 39s - loss: 0.2209 - acc: 0.9170\n",
      "Epoch 77/100\n",
      " - 40s - loss: 0.2204 - acc: 0.9175\n",
      "Epoch 78/100\n",
      " - 40s - loss: 0.2206 - acc: 0.9171\n",
      "Epoch 79/100\n",
      " - 42s - loss: 0.2211 - acc: 0.9168\n",
      "Epoch 80/100\n",
      " - 41s - loss: 0.2193 - acc: 0.9174\n",
      "Epoch 81/100\n",
      " - 42s - loss: 0.2202 - acc: 0.9173\n",
      "Epoch 82/100\n",
      " - 42s - loss: 0.2221 - acc: 0.9165\n",
      "Epoch 83/100\n",
      " - 42s - loss: 0.2214 - acc: 0.9166\n",
      "Epoch 84/100\n",
      " - 41s - loss: 0.2198 - acc: 0.9173\n",
      "Epoch 85/100\n",
      " - 39s - loss: 0.2194 - acc: 0.9175\n",
      "Epoch 86/100\n",
      " - 39s - loss: 0.2191 - acc: 0.9174\n",
      "Epoch 87/100\n",
      " - 38s - loss: 0.2188 - acc: 0.9177\n",
      "Epoch 88/100\n",
      " - 38s - loss: 0.2204 - acc: 0.9167\n",
      "Epoch 89/100\n",
      " - 39s - loss: 0.2186 - acc: 0.9180\n",
      "Epoch 90/100\n",
      " - 39s - loss: 0.2193 - acc: 0.9177\n",
      "Epoch 91/100\n",
      " - 42s - loss: 0.2182 - acc: 0.9183\n",
      "Epoch 92/100\n",
      " - 39s - loss: 0.2183 - acc: 0.9179\n",
      "Epoch 93/100\n",
      " - 40s - loss: 0.2173 - acc: 0.9181\n",
      "Epoch 94/100\n",
      " - 39s - loss: 0.2179 - acc: 0.9178\n",
      "Epoch 95/100\n",
      " - 41s - loss: 0.2165 - acc: 0.9186\n",
      "Epoch 96/100\n",
      " - 41s - loss: 0.2164 - acc: 0.9184\n",
      "Epoch 97/100\n",
      " - 42s - loss: 0.2180 - acc: 0.9181\n",
      "Epoch 98/100\n",
      " - 41s - loss: 0.2180 - acc: 0.9182\n",
      "Epoch 99/100\n",
      " - 42s - loss: 0.2164 - acc: 0.9186\n",
      "Epoch 100/100\n",
      " - 42s - loss: 0.2169 - acc: 0.9180\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x27c07d03588>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fit the momdel\n",
    "keras_nn.fit(X_train,  #<- training data\n",
    "            y_train,         #<- training labels\n",
    "            epochs = 100,    #<- number of epochs for weight backpropagation\n",
    "             batch_size=1000,\n",
    "             verbose = 2)     #<- we set this to 0 so we do not see every epoch run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140000/140000 [==============================] - ETA: 48 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 34 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 33 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 32 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 31 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 30 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 29 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 28 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 27 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 26 - ETA: 26 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 25 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 24 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 23 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 22 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 21 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 20 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 19 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 18 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 17 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 16 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 15 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 14 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 13 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 12 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 11 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 10 - ETA: 9 - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - ETA:  - 32s 231us/step\n",
      "('acc', 91.73)\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "keras_scores = keras_nn.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.73"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_scores[1]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_keras = keras_nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8487992742290897"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred_keras)\n",
    "\n",
    "metrics.auc(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
